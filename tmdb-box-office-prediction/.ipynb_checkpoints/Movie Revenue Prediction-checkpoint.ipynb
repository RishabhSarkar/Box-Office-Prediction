{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle tmdb-box-office-prediction competition\n",
    "\n",
    "https://www.kaggle.com/c/tmdb-box-office-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt      # matplotlib.pyplot plots data\n",
    "import seaborn as sns\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modified = pd.read_csv('train.csv/train.csv')\n",
    "df = df_modified\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Drop unique columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['imdb_id','id', 'title', 'tagline', 'poster_path', 'overview', 'original_title', 'budget'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NullCheckGraph(df):\n",
    "    df.isna().sum().plot(kind=\"barh\", figsize=(20,10))\n",
    "    for i, v in enumerate(df.isna().sum()):\n",
    "        plt.text(v, i, str(v), fontweight='bold', fontsize = 15)\n",
    "    plt.xlabel(\"Missing Value Count\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.title(\"Missing Value count By Features\")\n",
    "    \n",
    "NullCheckGraph(df)\n",
    "#NullZeroCount(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NullZeroCount(df):\n",
    "    print((df == 0).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NullZeroCount(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop column where 70% data is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['belongs_to_collection', 'homepage'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows with Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"cast\",\"production_companies\",\"production_countries\",\"crew\",\"spoken_languages\", \"Keywords\"],inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "NullCheckGraph(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning List column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch only name from genres column\n",
    "\n",
    "df['genres'] = df['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x,list) else [])\n",
    "\"\"\"\n",
    "genres_list = []\n",
    "\n",
    "#Gen all unique genres to create columns\n",
    "for genres_row in df['genres']:\n",
    "    #print(genres_row)\n",
    "    for j in range(len(genres_row)):\n",
    "        #print(genres_list)\n",
    "        genres_list.append(genres_row[j])\n",
    "\n",
    "unique_genres = list(set(genres_list))\n",
    "\n",
    "# Create separate column for all genres\n",
    "for i in unique_genres:\n",
    "    #print(i)\n",
    "    df[i] = pd.Series(data = 0)\n",
    "\n",
    "#Set respective genres to 1\n",
    "for i in range(len(df['genres'])):\n",
    "    if i in df['genres']:\n",
    "        genres_row = df['genres'][i]\n",
    "        for j in range(len(genres_row)):\n",
    "            #print(genres_row, genres_row[j])\n",
    "            col_name = genres_row[j]\n",
    "            #print(col_name)       \n",
    "            df.iloc[i,df.columns.get_loc(col_name)] = 1\n",
    "        #print(\"key error\")\n",
    "        #print(\"'break'\")\"\"\"\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "df = df.join(pd.DataFrame(mlb.fit_transform(df.pop('genres')), columns=mlb.classes_, index=df.index))\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Converting to list: cast, crew, production_companies, production_countries, spoken_languages column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Safely evaluate an expression node or a Unicode or Latin-1 encoded string containing a Python expression. \n",
    "The string or node provided may only consist of the following Python literal structures: strings, numbers, \n",
    "tuples, lists, dicts, booleans, and None. This can be used for safely evaluating strings containing Python expressions \n",
    "from untrusted sources without the need to parse the values oneself.\n",
    "\n",
    "Also read issue with CSV\n",
    "https://stackoverflow.com/questions/23111990/pandas-dataframe-stored-list-as-string-how-to-convert-back-to-list\n",
    "\n",
    "https://stackoverflow.com/questions/29552950/when-to-use-ast-literal-eval\"\"\"\n",
    "\n",
    "df['cast'] = df['cast'].apply(literal_eval)\n",
    "#df['crew'] = df['crew'].apply(literal_eval)\n",
    "#df['production_companies'] = df['production_companies'].apply(literal_eval)\n",
    "#df['production_countries'] = df['production_countries'].apply(literal_eval)\n",
    "#df['spoken_languages'] = df['spoken_languages'].apply(literal_eval)\n",
    "#df['keywords'] = df['keywords'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting feature from cast column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return np.nan\n",
    "    \n",
    "df['director'] = df['crew'].apply(get_director)\n",
    "\n",
    "#One hot encode \n",
    "dfDummies = pd.get_dummies(df['director'], prefix = 'director')\n",
    "df = pd.concat([df,dfDummies], axis=1)\n",
    "\n",
    "df['cast'] = df['cast'].apply(lambda x : [i['name'] for i in x] if isinstance(x,list) else [])\n",
    "\n",
    "df = df.join(pd.DataFrame(mlb.fit_transform(df.pop('cast')), columns=mlb.classes_, index=df.index))\n",
    "\n",
    "df.head(1)\n",
    "\n",
    "#df['cast'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning spoken_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['spoken_languages'] = df['spoken_languages'].apply(lambda x : [i['name'] for i in x] if isinstance(x,list) else [])\n",
    "\n",
    "df = df.join(pd.DataFrame(mlb.fit_transform(df.pop('spoken_languages')), columns=mlb.classes_, index=df.index))\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning production_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['production_companies'] = df['production_companies'].apply(lambda x : [i['name'] for i in x] if isinstance(x,list) else [])\n",
    "\n",
    "df = df.join(pd.DataFrame(mlb.fit_transform(df.pop('production_companies')), columns=mlb.classes_, index=df.index))\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning production_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['production_countries'] = df['production_countries'].apply(lambda x : [i['name'] for i in x] if isinstance(x,list) else [])\n",
    "\n",
    "df = df.join(pd.DataFrame(mlb.fit_transform(df.pop('production_countries')), columns=mlb.classes_, index=df.index))\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One hot encode Original_Language "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['original_language'] = np.where(df['original_language'] == 'en', 1, 0)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One hot encode Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDummies = pd.get_dummies(df['status'], prefix = 'status')\n",
    "\n",
    "df = pd.concat([df,dfDummies], axis=1)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get year from Date and One hot encode it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['release_date'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['release_date'] = pd.to_datetime(df['release_date'])\n",
    "#df['release_date'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['release_date'].dt.year\n",
    "\n",
    "#dfDummies = pd.get_dummies(df['year'], prefix = 'release_year')\n",
    "\n",
    "#df = pd.concat([df,dfDummies], axis=1)\n",
    "\n",
    "df['year'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One hot encode Director column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDummies = pd.get_dummies(df['director'], prefix = 'director')\n",
    "\n",
    "df = pd.concat([df,dfDummies], axis=1)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NullCheckGraph(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NullZeroCount(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop column after One-Hot encoding \n",
    "##### TODO: work on Keywords, crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['status', 'Keywords', 'crew', 'release_date', 'director'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[df.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NullCheckGraph(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find co related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(df, size=11):\n",
    "    \"\"\"\n",
    "    Function plots a graphical correlation matrix for each pair of columns in the dataframe.\n",
    "\n",
    "    Input:\n",
    "        df: pandas DataFrame\n",
    "        size: vertical and horizontal size of the plot\n",
    "\n",
    "    Displays:\n",
    "        matrix of correlation between columns.  Blue-cyan-yellow-red-darkred => less to more correlated\n",
    "                                                0 ------------------>  1\n",
    "                                                Expect a darkred line running from top left to bottom right\n",
    "    \"\"\"\n",
    "\n",
    "    corr = df.corr()    # data frame correlation function\n",
    "    fig, ax = plt.subplots(figsize=(size, size))\n",
    "    ax.matshow(corr)   # color code the rectangles by correlation value\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns)  # draw x tick marks\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)  # draw y tick marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_corr(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap(df.corr(), cmap='YlGnBu', annot = True, linewidths = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets explore our data more via charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"fig, axarr = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "df['status'].value_counts().head(5).plot.bar(ax=axarr[0][0], fontsize=12, color='mediumvioletred')\n",
    "ax=axarr[0][0].set_xlabel(\"status\", fontsize=18)\n",
    "df['budget'].value_counts().head(5).plot.bar(ax=axarr[0][1], fontsize=12, color='mediumvioletred')\n",
    "ax=axarr[0][1].set_title(\"budget\", fontsize=18)\n",
    "df['popularity'].value_counts().head(5).plot.bar(ax=axarr[1][0], fontsize=12, color='mediumvioletred')\n",
    "ax=axarr[1][1].set_xlabel(\"popularity\", fontsize=18)\n",
    "df['runtime'].value_counts().head(5).plot.bar(ax=axarr[1][1], fontsize=12, color='mediumvioletred')\n",
    "ax=axarr[1][1].set_xlabel(\"runtime\", fontsize=18)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"plt.figure(figsize=(20,10))\n",
    "plt.scatter(x = df['budget'], y = df['revenue'], marker = 'x', color = 'black')\n",
    "\n",
    "plt.xlabel('budget')\n",
    "plt.ylabel('revenue')\n",
    "plt.title('Buged impact')\n",
    "plt.legend()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"plt.figure(figsize=(20,10))\n",
    "plt.scatter(x = df['popularity'], y = df['revenue'], marker = 'x', color = 'black')\n",
    "\n",
    "plt.xlabel('popularity')\n",
    "plt.ylabel('revenue')\n",
    "plt.title('popularity impact')\n",
    "plt.legend()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"plt.figure(figsize=(20,10))\n",
    "plt.scatter(x = df['runtime'], y = df['revenue'], marker = 'x', color = 'black')\n",
    "\n",
    "plt.xlabel('runtime')\n",
    "plt.ylabel('revenue')\n",
    "plt.title('popularity impact')\n",
    "plt.legend()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"plt.figure(figsize=(20,10))\n",
    "plt.scatter(x = df['original_language'], y = df['revenue'], marker = 'x', color = 'black')\n",
    "\n",
    "plt.xlabel('original_language')\n",
    "plt.ylabel('revenue')\n",
    "plt.title('Language impact')\n",
    "plt.legend()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Null values from runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# ffill: propagate last valid observation forward to next valid\n",
    "# mean: takes mean of non-zero column and replaces zero with those. This should be modified\n",
    "#df['runtime'] = df['runtime'].fillna(method='ffill')\n",
    "mean_runtime = df['runtime'].mean(skipna=True)\n",
    "mean_budget = df['budget'].mean(skipna=True)\n",
    "df['runtime'] = df.runtime.replace(0, mean_runtime)\n",
    "df['budget'] = df.budget.replace(0, mean_budget)\n",
    "df.isna().any()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for 0 or Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#'runtime', 'budget','popularity','status'\n",
    "\n",
    "print(\"# rows in dataframe {0}\".format(len(df)))\n",
    "print(\"# rows null = %s, # of 0 = %s runtime\" %(len(df.loc[df['runtime'].isnull()]), len(df.loc[df['runtime'] == 0])))\n",
    "print(\"# rows null = %s, # of 0 = %s budget\" %(len(df.loc[df['budget'].isnull()]), len(df.loc[df['budget'] == 0])))\n",
    "print(\"# rows null = %s, # of 0 = %s popularity\" %(len(df.loc[df['popularity'].isnull()]), len(df.loc[df['popularity']== 0])))\n",
    "print(\"# rows null = %s, # of 0 = %s status\" %(len(df.loc[df['status'].isnull()]), len(df.loc[df['status'] == 0])))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "y = df.revenue\n",
    "\n",
    "X = X.drop(['revenue'], axis=1)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split training data into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_val,y_train, y_val = train_test_split(X,y,test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0:0.2f}% in training set\".format((len(X_train)/len(df.index)) * 100))\n",
    "print(\"{0:0.2f}% in test set\".format((len(X_val)/len(df.index)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Declare method used during model generic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSLE method to calculate RMSLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rmsle(y_v,y_p): \n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_v)-np.log1p(y_p)))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "def printResult(X, y, pred, xLabel, yLabel, title):\n",
    "    pyplot.scatter(X,y)\n",
    "    pyplot.plot(np.sort(X,axis=0), pred)\n",
    "    pyplot.xlabel(xLabel)\n",
    "    pyplot.ylabel(yLabel)\n",
    "    pyplot.title(title)\n",
    "    pyplot.legend()\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr_model.predict(X_val)\n",
    "\n",
    "joblib.dump(lr_model, 'LinearRegression_model.pkl', compress=9)\n",
    "\n",
    "print(\"RMSLE(used in Kaggle competition) score of Linear Model is {}\".format(rmsle(y_val,y_pred)))\n",
    "print(\"Accuracy: {0:.4f}\".format(lr_model.score(X_val,y_val)))\n",
    "print(\"MAE: {0:.4f}\".format(mean_absolute_error(y_pred, y_val)))\n",
    "\n",
    "#printResult(X_val.runtime, y_val, y_pred, 'runtime', 'revenue', 'Runtime impact on revnue')\n",
    "#printResult(X_val.budget, y_val, y_pred, 'budget', 'revenue', 'budget impact on revnue')\n",
    "#printResult(X_val.popularity, y_val, y_pred, 'popularity', 'revenue', 'popularity impact on revnue')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. RandomForestRegressor\n",
    "\n",
    "A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_val)\n",
    "\n",
    "joblib.dump(lr_model, 'RandomForestRegressor_model.pkl', compress=9)\n",
    "\n",
    "print(\"RMSLE score of Random Forest Model is {}\".format(rmsle(y_val,y_pred)))\n",
    "print(\"Accuracy: {0:.4f}\".format(rf_model.score(X_val,y_val)))\n",
    "print(\"MAE: {0:.4f}\".format(mean_absolute_error(y_pred, y_val)))\n",
    "\n",
    "#printResult(X_val.runtime, y_val, y_pred, 'runtime', 'revenue', 'Runtime impact on revnue')\n",
    "#printResult(X_val.budget, y_val, y_pred, 'budget', 'revenue', 'budget impact on revnue')\n",
    "#printResult(X_val.popularity, y_val, y_pred, 'popularity', 'revenue', 'popularity impact on revnue')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. KNeighborsRegressor\n",
    "\n",
    "The target is predicted by local interpolation of the targets associated of the nearest neighbors in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "kn_model = KNeighborsRegressor()\n",
    "kn_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = kn_model.predict(X_val)\n",
    "print(\"RMSLE score of KNeighborsRegressor Model is {}\".format(rmsle(y_val,y_pred)))\n",
    "print(\"Accuracy: {0:.4f}\".format(kn_model.score(X_val,y_val)))\n",
    "print(\"MAE: {0:.4f}\".format(mean_absolute_error(y_pred, y_val)))\n",
    "\n",
    "#printResult(X_val.runtime, y_val, y_pred, 'runtime', 'revenue', 'Runtime impact on revnue')\n",
    "#printResult(X_val.budget, y_val, y_pred, 'budget', 'revenue', 'budget impact on revnue')\n",
    "#printResult(X_val.popularity, y_val, y_pred, 'popularity', 'revenue', 'popularity impact on revnue')\n",
    "\n",
    "joblib.dump(lr_model, 'KNeighborsRegressor_model.pkl', compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from xgboost import XGBRegressor\n",
    "\n",
    "xg_regressor_model = XGBRegressor()\n",
    "xg_regressor_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xg_regressor_model.predict(X_val)\n",
    "\n",
    "joblib.dump(lr_model, 'XGBRegressor_model.pkl', compress=9)\n",
    "\n",
    "print(\"RMSLE score of XGBRegressor Model is {}\".format(rmsle(y_val,y_pred)))\n",
    "print(\"Accuracy: {0:.4f}\".format(xg_regressor_model.score(X_val,y_val)))\n",
    "print(\"MAE: {0:.4f}\".format(mean_absolute_error(y_pred, y_val)))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"End Of Project\" Check the directory, all the o/p files will be present there. We can upload the best one in the competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
